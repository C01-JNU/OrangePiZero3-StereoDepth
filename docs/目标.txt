# OrangePiZero3-StereoDepth 项目框架与现状
2026/1/17

## 🏗️ 项目总框架

### 一、系统架构层次

**硬件层**：
- 香橙派Zero3开发板（ARM Cortex-A53，Mali-G31 GPU）
- 双目摄像头（支持特定型号，如OV5640等）
- 计算资源：CPU + GPU协同

**软件基础层**：
- 操作系统：Linux（Ubuntu/Debian）
- Vulkan 1.0 API（GPU计算）
- OpenCV（图像处理）
- ROS2 Jazzy（消息通信）

**核心功能层**：

1. **摄像头子系统**：
   - 摄像头型号识别
   - 驱动程序适配
   - 实时图像捕获

2. **标定子系统**：
   - 棋盘格标定板检测
   - 自动图像采集（满足角点数量自动保存）
   - 双目标定计算
   - YAML格式标定参数输出

3. **深度计算引擎**：
   - **CPU模式**：传统立体匹配算法（备用）
   - **GPU模式（Vulkan）**：
     ```
     输入图像 → 金字塔构建 → Census变换 → 代价计算 → 
     WTA优化 → 中值滤波 → 一致性检查 → 输出视差图
     ```

4. **配置管理系统**：
   - YAML配置文件（统一参数管理）
   - 运行时模式切换（CPU/GPU）
   - 调试等级控制
   - ROS2参数生成

5. **ROS2集成层**：
   - 摄像头节点（图像发布）
   - 深度计算节点（视差/深度发布）
   - 参数服务器交互
   - 话题/服务接口

**构建与部署层**：
- CMake构建系统
- 着色器自动生成和编译
- 跨平台兼容性（ARM测试 + ARM部署）

### 二、核心数据处理流程

```
双目摄像头
    ↓
实时图像捕获
    ↓
[可选] 相机标定校正
    ↓
图像预处理（灰度化、缩放）
    ↓
    ├── CPU模式：传统立体匹配算法
    ↓
    └── GPU模式：Vulkan计算流水线
        ↓
    着色器参数配置
        ↓
    SPIR-V着色器编译
        ↓
    GPU内存分配与数据传输
        ↓
    多阶段计算管线执行
        ↓
    结果下载与后处理
    ↓
视差图 → 深度图 → 点云
    ↓
ROS2话题发布
    ↓
可视化/存储/应用
```

### 三、关键模块设计

1. **配置中心** (`config/`)：
   - `global_config.yaml`：全局参数（调试等级、模式选择等）
   - `shaders.yaml`：着色器专用参数
   - 运行时动态加载和热重载

2. **Vulkan核心** (`vulkan/`)：
   - 上下文管理、资源生命周期
   - 计算管线管理器
   - 着色器模板和编译系统

3. **图像处理** (`utils/`)：
   - OpenCV封装工具
   - 立体图像分割
   - 批量处理支持

4. **主应用程序**：
   - 命令行界面
   - 流水线调度器
   - 性能监控和日志

5. **测试系统**：
   - 单元测试（Vulkan基础功能）
   - 集成测试（完整流水线）
   - 性能基准测试

### 🔄 与原始目标的偏差

1. **配置系统**：原计划使用`vulkan_config.h`，现改为YAML格式，或者其它适配性更强的格式，但是不论如何只能有一个总配置文件

2. **摄像头适配**：原计划多型号支持，当前聚焦特定型号
   - 简化了驱动复杂性
     但是配置文件里不应该出现摄像头的输入通道(/dev/video1之类的)，摄像头相关的放心交给摄像头驱动文件提供的API即可

3.需要新建一个文件夹用来存放三种图像
第一种：测试用图像
第二种：输出图像，把测试用的图像加工后输出到此处
第三种：标定用图像，自动捕获程序会把捕获的图像放到此次，标定程序从此处读取图像